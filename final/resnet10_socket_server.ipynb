{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import socket\n",
    "import struct\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import psutil\n",
    "random.seed(0)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.initial_seed(), \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "# Check if CUDA is available, else use CPU\n",
    "#device = \"cpu\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "USERS = 1\n",
    "CUT_LAYER = 1\n",
    "BOTTLENECK_COMPRESSION = 4\n",
    "QUANTIZATION_REQUIRED = 1 # 1 for required\n",
    "QUANTIZATION_TYPE = torch.qint8 # np.uint8, np.int8, np.uint16, np.int16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_msg(sock, msg):\n",
    "    # prefix each message with a 4-byte length in network byte order\n",
    "    msg = pickle.dumps(msg)\n",
    "    msg = struct.pack('>I', len(msg)) + msg\n",
    "    sock.sendall(msg)\n",
    "    return len(msg)\n",
    "\n",
    "def recv_msg(sock):\n",
    "    # read message length and unpack it into an integer\n",
    "    raw_msglen = recvall(sock, 4)\n",
    "    if not raw_msglen:\n",
    "        return None\n",
    "    msglen = struct.unpack('>I', raw_msglen)[0]\n",
    "    # read the message data\n",
    "    msg =  recvall(sock, msglen)\n",
    "    msg = pickle.loads(msg)\n",
    "    return msg, msglen\n",
    "\n",
    "def recvall(sock, n):\n",
    "    # helper function to receive n MB or return None if EOF is hit\n",
    "    data = b''\n",
    "    while len(data) < n:\n",
    "        packet = sock.recv(n - len(data))\n",
    "        if not packet:\n",
    "            return None\n",
    "        data += packet\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = 'localhost'\n",
    "port = 12313\n",
    "\n",
    "s = socket.socket()\n",
    "s.bind((host, port))\n",
    "s.listen(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conn:  <socket.socket fd=3400, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 12313), raddr=('127.0.0.1', 57960)>\n",
      "Conntected with ('127.0.0.1', 57960)\n",
      "Total batch {} 100\n"
     ]
    }
   ],
   "source": [
    "clientsoclist = []\n",
    "train_total_batch = []\n",
    "val_acc = []\n",
    "\n",
    "total_sendsize_list = []\n",
    "total_receivesize_list = []\n",
    "\n",
    "client_sendsize_list = [[] for i in range(USERS)]\n",
    "client_receivesize_list = [[] for i in range(USERS)]\n",
    "\n",
    "train_sendsize_list = [] \n",
    "train_receivesize_list = []\n",
    "\n",
    "send_time_list = [[] for i in range(USERS)]\n",
    "recv_time_list = [[] for i in range(USERS)]\n",
    "total_time_list = [[] for i in range(USERS)]\n",
    "\n",
    "send_bandwidth_list = [[] for i in range(USERS)]\n",
    "recv_bandwidth_list = [[] for i in range(USERS)]\n",
    "total_bandwidth_list = [[] for i in range(USERS)]\n",
    "\n",
    "loss_list = [[] for i in range(USERS)]\n",
    "\n",
    "for i in range(USERS):\n",
    "    conn, addr = s.accept()\n",
    "    print(\"conn: \", conn)\n",
    "    print('Conntected with', addr)\n",
    "    clientsoclist.append(conn)    # append client socket on list\n",
    "    msg = {\n",
    "            'epochs': EPOCHS,\n",
    "            'users': USERS,\n",
    "            'cut_layer': CUT_LAYER,\n",
    "            'bottleneck_compression': BOTTLENECK_COMPRESSION,\n",
    "            'quantization_required': QUANTIZATION_REQUIRED,\n",
    "            'QUANTIZATION_TYPE': QUANTIZATION_TYPE\n",
    "    }\n",
    "    datasize = send_msg(conn, msg)    #send epoch\n",
    "    total_sendsize_list.append(sys.getsizeof(msg))\n",
    "    client_sendsize_list[i].append(sys.getsizeof(msg))\n",
    "\n",
    "    total_batch, datasize = recv_msg(conn)    # get total_batch of train dataset\n",
    "    print(\"Total batch {}\", total_batch)\n",
    "    total_receivesize_list.append(sys.getsizeof(total_batch))\n",
    "    client_receivesize_list[i].append(sys.getsizeof(total_batch))\n",
    "\n",
    "    train_total_batch.append(total_batch)    # append on list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClientResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bl_encoder): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ClientResNet(nn.Module):\n",
    "    def __init__(self, block, output_channel=[64,128,256,512], stride=[1,2,2,2], num_blocks=[1,1,1,1], num_classes=10, \n",
    "                 bottleneck_compression=4, cut_layer=1):\n",
    "        super(ClientResNet, self).__init__()\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        self.output_channel = output_channel\n",
    "        self.stride = stride\n",
    "        self.num_blocks = num_blocks\n",
    "        self.num_classes = num_classes\n",
    "        self.bottleneck_compression = bottleneck_compression\n",
    "        self.cut_layer = cut_layer\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layers = []\n",
    "        for layer in range(0, self.cut_layer):\n",
    "            self.layers.append(self._make_layer(block, self.output_channel[layer], self.num_blocks[layer], stride=self.stride[layer]))\n",
    "        self.conv_layers = nn.Sequential(*self.layers)\n",
    "\n",
    "        if self.bottleneck_compression>=1:\n",
    "            self.bl_encoder = nn.Conv2d(output_channel[self.cut_layer-1], output_channel[self.cut_layer-1]//bottleneck_compression, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.maxpool(out)\n",
    "        out = self.conv_layers(out)\n",
    "        if self.bottleneck_compression>=1:\n",
    "            out = self.bl_encoder(out)\n",
    "        return out\n",
    "\n",
    "# Create the model\n",
    "client_model = ClientResNet(block=BasicBlock, bottleneck_compression=BOTTLENECK_COMPRESSION, cut_layer=CUT_LAYER)\n",
    "client_model = client_model.to(device)\n",
    "print(client_model)\n",
    "#print(client_model.conv_layers[0][0].conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ServerResNet(\n",
      "  (bl_decoder): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ServerResNet(nn.Module):\n",
    "    def __init__(self, block, output_channel=[64,128,256,512], stride=[1,2,2,2], num_blocks=[1,1,1,1], num_classes=10, \n",
    "                 bottleneck_compression=4, cut_layer=1):\n",
    "        super(ServerResNet, self).__init__()\n",
    "\n",
    "        self.output_channel = output_channel\n",
    "        self.stride = stride\n",
    "        self.num_blocks = num_blocks\n",
    "        self.num_classes = num_classes\n",
    "        self.bottleneck_compression = bottleneck_compression\n",
    "        self.cut_layer = cut_layer\n",
    "        self.in_channels = self.output_channel[self.cut_layer-1]\n",
    "        \n",
    "\n",
    "        if self.bottleneck_compression>=1:\n",
    "            self.bl_decoder = nn.Conv2d(self.output_channel[self.cut_layer-1]//self.bottleneck_compression, self.output_channel[self.cut_layer-1], kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    \n",
    "        self.layers = []\n",
    "        for layer in range(self.cut_layer, 4):\n",
    "            self.layers.append(self._make_layer(block, self.output_channel[layer], self.num_blocks[layer], stride=self.stride[layer]))\n",
    "        self.conv_layers = nn.Sequential(*self.layers)\n",
    " \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, self.num_classes)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        if self.bottleneck_compression>=1:\n",
    "            x = self.bl_decoder(x)\n",
    "        out = self.conv_layers(x)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Create the model\n",
    "server_model = ServerResNet(block=BasicBlock, output_channel=[64,128,256,512], stride=[1,2,2,2], num_blocks=[1,1,1,1], num_classes=10, \n",
    "                 bottleneck_compression=BOTTLENECK_COMPRESSION, cut_layer=CUT_LAYER)\n",
    "server_model = server_model.to(device)\n",
    "print(server_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(server_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_tensor(tensor, quantization_type):\n",
    "\n",
    "    min_val, max_val = tensor.min(), tensor.max()\n",
    "\n",
    "    if quantization_type == torch.quint8:\n",
    "        scale = torch.tensor((max_val - min_val) / 255)\n",
    "        zero_point = torch.tensor(max(0, min(255, int(-min_val / scale))))\n",
    "        return torch.quantize_per_tensor(tensor, scale, zero_point, torch.quint8)\n",
    "\n",
    "    elif quantization_type == torch.qint8:\n",
    "        scale = torch.tensor(max_val / 127 if max_val.abs() > min_val.abs() else min_val / -128)\n",
    "        zero_point = torch.tensor(0)  # For qint8, zero_point is typically set to 0 for symmetric quantization\n",
    "        return torch.quantize_per_tensor(tensor, scale, zero_point, torch.qint8)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid quantization type. Choose 'quint8' or 'qint8'.\")\n",
    "\n",
    "def dequantize_tensor(quantized_tensor):\n",
    "    return torch.dequantize(quantized_tensor).requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timer start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Client0 : 100%|███████████████████████████████████████████| 100/100 [00:34<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(1.3578, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Client0 : 100%|███████████████████████████████████████████| 100/100 [00:31<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(1.1376, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Client0 : 100%|███████████████████████████████████████████| 100/100 [00:30<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(1.0491, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Client0 : 100%|███████████████████████████████████████████| 100/100 [00:30<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(0.9083, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Client0 : 100%|███████████████████████████████████████████| 100/100 [00:30<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(0.8714, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Client0 : 100%|███████████████████████████████████████████| 100/100 [00:30<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(0.7032, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Client0 : 100%|███████████████████████████████████████████| 100/100 [00:30<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(0.6476, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Client0 : 100%|███████████████████████████████████████████| 100/100 [00:30<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(0.5456, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Client0 : 100%|███████████████████████████████████████████| 100/100 [00:30<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(0.5412, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Client0 : 100%|██████████████████████████████████████████| 100/100 [00:30<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(0.4351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train is done\n",
      "TrainingTime: 315.1170630455017 sec\n"
     ]
    }
   ],
   "source": [
    "client_weights = copy.deepcopy(client_model.state_dict())\n",
    "\n",
    "start_time = time.time()    # store start time\n",
    "print(\"timer start!\")\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "\n",
    "    # train client 0\n",
    "    for user in range(USERS):\n",
    "\n",
    "        datasize = send_msg(clientsoclist[user], client_weights)\n",
    "        total_sendsize_list.append(datasize)\n",
    "        client_sendsize_list[user].append(datasize)\n",
    "        train_sendsize_list.append(datasize)\n",
    "\n",
    "        recv_time_total = 0\n",
    "        send_time_total = 0\n",
    "        total_time = 0\n",
    "\n",
    "        for i in tqdm(range(train_total_batch[user]), ncols=100, desc='Epoch {} Client{} '.format(e+1, user)):\n",
    "            optimizer.zero_grad()  # initialize all gradients to zero\n",
    "\n",
    "            recv_start_time = time.time()\n",
    "            msg, datasize = recv_msg(clientsoclist[user])  # receive client message from socket\n",
    "            recv_end_time = time.time()\n",
    "\n",
    "            recv_time = recv_end_time - recv_start_time\n",
    "            recv_time_total += recv_time\n",
    "            recv_time_avg = recv_time_total/(i+1)\n",
    "\n",
    "            total_receivesize_list.append(datasize)\n",
    "            client_receivesize_list[user].append(datasize)\n",
    "            train_receivesize_list.append(datasize)\n",
    "\n",
    "            client_output = msg['client_output']  # client output tensor\n",
    "            label = msg['label']  # label\n",
    "            label = label.clone().detach().long()\n",
    "            label = label.to(device)\n",
    "            \n",
    "            if QUANTIZATION_REQUIRED == 1:\n",
    "                client_output = dequantize_tensor(client_output)\n",
    "            \n",
    "            output = server_model(client_output).to(device)  # forward propagation\n",
    "            loss = criterion(output, label)  # calculates cross-entropy loss\n",
    "            loss.backward()  # backward propagation   \n",
    "                \n",
    "            if QUANTIZATION_REQUIRED == 1:\n",
    "                msg = quantize_tensor(client_output.grad.clone().detach().requires_grad_(True), QUANTIZATION_TYPE)\n",
    "            \n",
    "            else:\n",
    "                msg = client_output.grad.clone().detach().requires_grad_(True)\n",
    "            \n",
    "            send_start_time = time.time()\n",
    "            datasize = send_msg(clientsoclist[user], msg)\n",
    "            send_end_time = time.time()\n",
    "\n",
    "            send_time = send_end_time - send_start_time\n",
    "            send_time_total += send_time\n",
    "            send_time_avg = send_time_total/(i+1)\n",
    "\n",
    "            total_sendsize_list.append(datasize)\n",
    "            client_sendsize_list[user].append(datasize)\n",
    "            train_sendsize_list.append(datasize)\n",
    "\n",
    "            total_time += (send_time + recv_time)\n",
    "            total_time_avg = total_time/(i+1)\n",
    "            \n",
    "            optimizer.step()\n",
    "        \n",
    "           \n",
    "        client_weights, datasize = recv_msg(clientsoclist[user])\n",
    "        total_receivesize_list.append(datasize)\n",
    "        client_receivesize_list[user].append(datasize)\n",
    "        train_receivesize_list.append(datasize)\n",
    "        \n",
    "        send_time_list[user].append(send_time_avg)\n",
    "        recv_time_list[user].append(recv_time_avg)\n",
    "        total_time_list[user].append(total_time_avg)\n",
    "\n",
    "    print(\"Loss: \", loss)\n",
    "    loss_list[user].append(loss.cpu().detach().numpy()) \n",
    "        \n",
    "        \n",
    "print('train is done')\n",
    "\n",
    "end_time = time.time()  # store end time\n",
    "print(\"TrainingTime: {} sec\".format(end_time - start_time))\n",
    "\n",
    "# Let's quickly save our trained model:\n",
    "PATH = './server_model_state_dict.pth'\n",
    "torch.save(server_model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_list = list(range(1, EPOCHS + 1))\n",
    "#loss_list = loss_list[0]\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_list, loss_list[0])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "client_model.load_state_dict(client_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    corr_num = 0\n",
    "    total_num = 0\n",
    "    val_loss = 0.0\n",
    "    for i, val in enumerate(tqdm(trainloader, desc=\"Training Data\")):\n",
    "        val_x, val_label = val\n",
    "        val_x = val_x.to(device)\n",
    "        val_label = val_label.to(device)\n",
    "\n",
    "        val_output = client_model(val_x)\n",
    "        val_label = val_label.long()\n",
    "        \n",
    "        val_output = server_model(val_output)\n",
    "        \n",
    "        loss = criterion(val_output, val_label)\n",
    "        val_loss += loss.item()\n",
    "        model_label = val_output.argmax(dim=1)\n",
    "        corr = val_label[val_label == model_label].size(0)\n",
    "        corr_num += corr\n",
    "        total_num += val_label.size(0)\n",
    "    print(\"train_acc: {:.2f}%, train_loss: {:.4f}\".format(corr_num / total_num * 100, val_loss / len(trainloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    corr_num = 0\n",
    "    total_num = 0\n",
    "    val_loss = 0.0\n",
    "    for i, val in enumerate(tqdm(testloader, desc=\"Testing Data\")):\n",
    "        val_x, val_label = val\n",
    "        val_x = val_x.to(device)\n",
    "        val_label = val_label.to(device)\n",
    "\n",
    "        val_output = client_model(val_x)\n",
    "        val_label = val_label.long()\n",
    "        \n",
    "        val_output = server_model(val_output)\n",
    "        \n",
    "        loss = criterion(val_output, val_label)\n",
    "        val_loss += loss.item()\n",
    "        model_label = val_output.argmax(dim=1)\n",
    "        corr = val_label[val_label == model_label].size(0)\n",
    "        corr_num += corr\n",
    "        total_num += val_label.size(0)\n",
    "    print(\"test_acc: {:.2f}%, test_loss: {:.4f}\".format(corr_num / total_num * 100, val_loss / len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(tqdm(testloader, desc=\"Testing Data\")):\n",
    "        x, labels = data\n",
    "        x = x.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = client_model(x)\n",
    "        outputs = server_model(outputs)\n",
    "        labels = labels.long()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thop import profile\n",
    "x =  torch.randn(50000, 3, 32, 32)\n",
    "x = x.to(device)\n",
    "macs, params = profile(client_model, inputs=(x,))\n",
    "print(macs, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thop import profile\n",
    "x =  torch.randn(client_output.shape)\n",
    "x = x.to(device)\n",
    "macs, params = profile(server_model, inputs=(x,))\n",
    "print(macs, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'path_to_file' with your file path\n",
    "file_path = 'server_model_state_dict.pth'\n",
    "\n",
    "# Get the size of the file in bytes\n",
    "file_size = os.path.getsize(file_path)\n",
    "\n",
    "print(f\"The size of the file is {file_size / (1024**2)} MB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Current Memory Usage: {psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_send_total_size_list = [[] for i in range(USERS)]\n",
    "client_recv_total_size_list = [[] for i in range(USERS)]\n",
    "\n",
    "print('---total_sendsize_list---')\n",
    "totalsend_size = 0\n",
    "for size in total_sendsize_list:\n",
    "    totalsend_size += size\n",
    "print(\"total_sendsize size: {} MB\".format(totalsend_size/(1024**2)))\n",
    "print(\"number of total_send: \", len(total_sendsize_list))\n",
    "print('\\n')\n",
    "\n",
    "print('---total_receivesize_list---')\n",
    "total_receive_size = 0\n",
    "for size in total_receivesize_list:\n",
    "    total_receive_size += size\n",
    "print(\"total receive sizes: {} MB\".format(total_receive_size/(1024**2)) )\n",
    "print(\"number of total receive: \", len(total_receivesize_list) )\n",
    "print('\\n')\n",
    "\n",
    "for i in range(USERS):\n",
    "    print('---client_sendsize_list(user{})---'.format(i))\n",
    "    total_size = 0\n",
    "    for size in client_sendsize_list[i]:\n",
    "#         print(size)\n",
    "        total_size += size\n",
    "    client_send_total_size_list[i] = total_size\n",
    "    print(\"total client_sendsizes(user{}): {} MB\".format(i, client_send_total_size_list[i]/(1024**2)))\n",
    "    print(\"number of client_send(user{}): \".format(i), len(client_sendsize_list[i]))\n",
    "    print('\\n')\n",
    "\n",
    "    print('---client_receivesize_list(user{})---'.format(i))\n",
    "    total_size = 0\n",
    "    for size in client_receivesize_list[i]:\n",
    "#         print(size)\n",
    "        total_size += size\n",
    "    client_recv_total_size_list[i] = total_size\n",
    "    print(\"total client_receive sizes(user{}): {} MB\".format(i, client_recv_total_size_list[i]/(1024**2)))\n",
    "    print(\"number of client_send(user{}): \".format(i), len(client_receivesize_list[i]))\n",
    "    print('\\n')\n",
    "\n",
    "print('---train_sendsize_list---')\n",
    "total_size = 0\n",
    "for size in train_sendsize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "train_sendsize = total_size\n",
    "print(\"total train_sendsizes: {} MB\".format(train_sendsize/(1024**2)))\n",
    "print(\"number of train_send: \", len(train_sendsize_list) )\n",
    "print('\\n')\n",
    "\n",
    "print('---train_receivesize_list---')\n",
    "total_size = 0\n",
    "for size in train_receivesize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "train_recvsize = total_size\n",
    "print(\"total train_receivesizes: {} MB\".format(train_recvsize/(1024**2)))\n",
    "print(\"number of train_receive: \", len(train_receivesize_list) )\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(USERS):\n",
    "    print('client_send_time(user{}) - {} seconds'.format(i, send_time_list[i]))\n",
    "\n",
    "for i in range(USERS):\n",
    "    print('client_receive_time(user{}) - {} seconds'.format(i, recv_time_list[i]))\n",
    "\n",
    "for i in range(USERS):\n",
    "    print('client_total_time(user{}) - {} seconds'.format(i, total_time_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(USERS):\n",
    "    print('client_send_bandwidth(user{}) - {} MB/sec'.format(i, (client_send_total_size_list[i]/send_time_list[i][0])/(1024**2)))\n",
    "\n",
    "for i in range(USERS):\n",
    "    print('client_receive_bandwidth(user{}) - {} MB/sec'.format(i, (client_recv_total_size_list[i]/recv_time_list[i][0])/(1024**2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
