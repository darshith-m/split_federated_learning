{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import socket\n",
    "import struct\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import sys\n",
    "import psutil\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.initial_seed(), \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_msg(sock, msg):\n",
    "    # prefix each message with a 4-byte length in network byte order\n",
    "    msg = pickle.dumps(msg)\n",
    "    msg = struct.pack('>I', len(msg)) + msg\n",
    "    sock.sendall(msg)\n",
    "\n",
    "def recv_msg(sock):\n",
    "    # read message length and unpack it into an integer\n",
    "    raw_msglen = recvall(sock, 4)\n",
    "    if not raw_msglen:\n",
    "        return None\n",
    "    msglen = struct.unpack('>I', raw_msglen)[0]\n",
    "    # read the message data\n",
    "    msg =  recvall(sock, msglen)\n",
    "    msg = pickle.loads(msg)\n",
    "    return msg\n",
    "\n",
    "def recvall(sock, n):\n",
    "    # helper function to receive n bytes or return None if EOF is hit\n",
    "    data = b''\n",
    "    while len(data) < n:\n",
    "        packet = sock.recv(n - len(data))\n",
    "        if not packet:\n",
    "            return None\n",
    "        data += packet\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS: 10\n",
      "USERS: 1\n",
      "CUT_LAYER: 1\n",
      "BOTTLENECK_COMPRESSION: 4\n",
      "QUANTIZATION_REQUIRED: 1\n",
      "QUANTIZATION_TYPE: torch.qint8\n"
     ]
    }
   ],
   "source": [
    "host = 'localhost'\n",
    "port = 12313\n",
    "s = socket.socket()\n",
    "s.connect((host, port))\n",
    "msg_r = recv_msg(s)\n",
    "\n",
    "EPOCHS = msg_r['epochs']\n",
    "USERS = msg_r['users']\n",
    "CUT_LAYER = msg_r['cut_layer']\n",
    "BOTTLENECK_COMPRESSION = msg_r['bottleneck_compression']\n",
    "QUANTIZATION_REQUIRED = msg_r['quantization_required']\n",
    "QUANTIZATION_TYPE = msg_r['QUANTIZATION_TYPE']\n",
    "\n",
    "print(f\"EPOCHS: {EPOCHS}\")\n",
    "print(f\"USERS: {USERS}\")\n",
    "print(f\"CUT_LAYER: {CUT_LAYER}\")\n",
    "print(f\"BOTTLENECK_COMPRESSION: {BOTTLENECK_COMPRESSION}\")\n",
    "print(f\"QUANTIZATION_REQUIRED: {QUANTIZATION_REQUIRED}\")\n",
    "print(f\"QUANTIZATION_TYPE: {QUANTIZATION_TYPE}\")\n",
    "\n",
    "msg = len(trainloader)\n",
    "send_msg(s, msg)   # send total_batch of train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClientResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bl_encoder): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ClientResNet(nn.Module):\n",
    "    def __init__(self, block, output_channel=[64,128,256,512], stride=[1,2,2,2], num_blocks=[1,1,1,1], num_classes=10, \n",
    "                 bottleneck_compression=4, cut_layer=1):\n",
    "        super(ClientResNet, self).__init__()\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        self.output_channel = output_channel\n",
    "        self.stride = stride\n",
    "        self.num_blocks = num_blocks\n",
    "        self.num_classes = num_classes\n",
    "        self.bottleneck_compression = bottleneck_compression\n",
    "        self.cut_layer = cut_layer\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layers = []\n",
    "        for layer in range(0, self.cut_layer):\n",
    "            self.layers.append(self._make_layer(block, self.output_channel[layer], self.num_blocks[layer], stride=self.stride[layer]))\n",
    "        self.conv_layers = nn.Sequential(*self.layers)\n",
    "\n",
    "        if self.bottleneck_compression>=1:\n",
    "            self.bl_encoder = nn.Conv2d(output_channel[self.cut_layer-1], output_channel[self.cut_layer-1]//bottleneck_compression, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.maxpool(out)\n",
    "        out = self.conv_layers(out)\n",
    "        if self.bottleneck_compression>=1:\n",
    "            out = self.bl_encoder(out)\n",
    "        return out\n",
    "\n",
    "# Create the model\n",
    "client_model = ClientResNet(block=BasicBlock, bottleneck_compression=BOTTLENECK_COMPRESSION, cut_layer=CUT_LAYER)\n",
    "client_model = client_model.to(device)\n",
    "print(client_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_tensor(tensor, quantization_type):\n",
    "\n",
    "    min_val, max_val = tensor.min(), tensor.max()\n",
    "\n",
    "    if quantization_type == torch.quint8:\n",
    "        scale = torch.tensor((max_val - min_val) / 255)\n",
    "        zero_point = torch.tensor(max(0, min(255, int(-min_val / scale))))\n",
    "        return torch.quantize_per_tensor(tensor, scale, zero_point, torch.quint8)\n",
    "\n",
    "    elif quantization_type == torch.qint8:\n",
    "        scale = torch.tensor(max_val / 127 if max_val.abs() > min_val.abs() else min_val / -128)\n",
    "        zero_point = torch.tensor(0)  # For qint8, zero_point is typically set to 0 for symmetric quantization\n",
    "        return torch.quantize_per_tensor(tensor, scale, zero_point, torch.qint8)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid quantization type. Choose 'quint8' or 'qint8'.\")\n",
    "\n",
    "def dequantize_tensor(quantized_tensor):\n",
    "    return torch.dequantize(quantized_tensor).requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(client_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|████████████████████████████████████████████████████| 100/100 [00:35<00:00,  2.84it/s]\n",
      "Epoch 2: 100%|████████████████████████████████████████████████████| 100/100 [00:31<00:00,  3.17it/s]\n",
      "Epoch 3: 100%|████████████████████████████████████████████████████| 100/100 [00:30<00:00,  3.25it/s]\n",
      "Epoch 4: 100%|████████████████████████████████████████████████████| 100/100 [00:31<00:00,  3.22it/s]\n",
      "Epoch 5: 100%|████████████████████████████████████████████████████| 100/100 [00:30<00:00,  3.24it/s]\n",
      "Epoch 6: 100%|████████████████████████████████████████████████████| 100/100 [00:31<00:00,  3.20it/s]\n",
      "Epoch 7: 100%|████████████████████████████████████████████████████| 100/100 [00:30<00:00,  3.23it/s]\n",
      "Epoch 8: 100%|████████████████████████████████████████████████████| 100/100 [00:30<00:00,  3.23it/s]\n",
      "Epoch 9: 100%|████████████████████████████████████████████████████| 100/100 [00:30<00:00,  3.26it/s]\n",
      "Epoch 10: 100%|███████████████████████████████████████████████████| 100/100 [00:31<00:00,  3.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    client_weights = recv_msg(s)\n",
    "    client_model.load_state_dict(client_weights, strict=False)\n",
    "    client_model.eval()\n",
    "    for i, data in enumerate(tqdm(trainloader, ncols=100, desc='Epoch '+str(e+1))):\n",
    "        \n",
    "        x, label = data\n",
    "        \n",
    "        x = x.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = client_model(x)\n",
    "\n",
    "        if QUANTIZATION_REQUIRED==1:\n",
    "            output_quantized = quantize_tensor(output, QUANTIZATION_TYPE)\n",
    "            msg = {\n",
    "                'client_output': output_quantized,\n",
    "                'label': label,\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            msg = {\n",
    "                'client_output': output,\n",
    "                'label': label,\n",
    "            }\n",
    "\n",
    "        send_msg(s, msg)\n",
    "        \n",
    "        client_grad = recv_msg(s)\n",
    "        \n",
    "        if QUANTIZATION_REQUIRED==1:\n",
    "            client_grad = dequantize_tensor(client_grad)\n",
    "\n",
    "        output.backward(client_grad)\n",
    "        optimizer.step()\n",
    "    send_msg(s, client_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the file is 0.3619508743286133 MB.\n"
     ]
    }
   ],
   "source": [
    "torch.save(client_model.state_dict(), 'client_model_state_dict.pth')\n",
    "\n",
    "# Replace 'path_to_file' with your file path\n",
    "file_path = 'client_model_state_dict.pth'\n",
    "\n",
    "# Get the size of the file in bytes\n",
    "file_size = os.path.getsize(file_path)\n",
    "\n",
    "print(f\"The size of the file is {file_size / (1024**2)} MB.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Memory Usage: 910.2265625 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current Memory Usage: {psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
